\documentclass[12pt]{article}
\usepackage{verbatim, amsmath,amssymb,amsthm,graphicx}
\usepackage[margin=1in,nohead]{geometry}
\usepackage{sectsty}
\usepackage{float}
\usepackage{natbib}
\usepackage[usenames]{color}
\usepackage{xspace}
\usepackage{subfig}
\usepackage{bbm}
\usepackage{bm}

\sectionfont{\normalsize}
\subsectionfont{\small}

\title{}
\date{}
\author{}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\newcommand{\Remark}[2]{{\color{red}Remark from #1: #2}\xspace}
\newcommand{\argmin}[1]{\underset{#1}{\operatorname{argmin}}\text{ }}
\newcommand{\argmax}[1]{\underset{#1}{\operatorname{argmax}}\text{ }}
\newcommand{\minimax}[2]{\argmin{#1}\underset{#2}{\operatorname{max}}}
\newcommand{\bb}{\textbf{b}}

\newcommand{\Var}{\text{Var }}
\newcommand{\Cov}{\text{Cov }}
\newcommand{\E}{\mathbb{E}}
\newcommand{\ind}{\mathbbm{1}}

\newcommand{\V}[1]{{\bm{\mathbf{\MakeLowercase{#1}}}}} % vector
\newcommand{\M}[1]{{\bm{\mathbf{\MakeUppercase{#1}}}}} % matrix

\newcommand{\todo}[1]{{\color{red}TODO: #1}}

\newenvironment{my_enumerate}{
  \begin{enumerate}
    \setlength{\itemsep}{1pt}
    \setlength{\parskip}{0pt}
    \setlength{\parsep}{0pt}}{\end{enumerate}
}



% Alter some LaTeX defaults for better treatment of figures:
% See p.105 of [yas] elisp error!TeX Unbound'' for suggested values.
% See pp. 199-200 of Lamport's [yas] elisp error!LaTeX'' book for details.
%   General parameters, for ALL pages:
\renewcommand{\topfraction}{0.9}% max fraction of floats at top
\renewcommand{\bottomfraction}{0.8}% max fraction of floats at bottom
%   Parameters for TEXT pages (not float pages):
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}     % 2 may work better
\setcounter{dbltopnumber}{2}    % for 2-column pages
\renewcommand{\dbltopfraction}{0.9}% fit big float above 2-col. text
\renewcommand{\textfraction}{0.07}% allow minimal text w. figs
%   Parameters for FLOAT pages (not text pages):
\renewcommand{\floatpagefraction}{0.7}% require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\renewcommand{\dblfloatpagefraction}{0.7}% require fuller float pages

% remember to use [htp] or [htpb] for placement





\begin{document}
\noindent
\textbf{James Long}\\
\textbf{\today}\\
\textbf{Estimating Band Means and Dust}

\section{Model}

Let $m_{ib}$ be the mean magnitude of light curve $i$ in band $b$. We model
\begin{equation*}
m_{ib} = \beta_b + \alpha_i + d_i\delta_b + \sigma_{ib}
\end{equation*}
where $\beta_b$ is the mean offset for band $b$, $\alpha_i$ is the mean brightness of light curve $i$, $d_i$ is the amount of dust, $\delta_b$ is the extinction due to dust in band $b$, and $\sigma_{ib} \sim N(0,\sigma^2)$ independent. We can rewrite the model in vector form as
\begin{equation*}
\V{m}_i = \V{\beta} + \alpha_i \V{1} + d_i \V{\delta} + \V{\sigma}_i
\end{equation*}
where $\V{\sigma}_i \sim N(0,\sigma^2I)$. The model is not identifiable. For example,
\begin{align*}
\V{m}_i &= (\V{\beta} + c\V{\delta}) + \alpha_i \V{1} + (d_i - c) \V{\delta} + \V{\sigma}_i\\
\V{m}_i &= (\V{\beta} - c\V{1}) + (\alpha_i + c)\V{1} + d_i\V{\delta} + \V{\sigma}_i\\
\V{m}_i &= \V{\beta} + (\alpha_i - d_i)\V{1} + d_i(\V{\delta} + 1) + \V{\sigma}_i\\
\end{align*}
For identifiability we assume $\V{\delta} \perp \V{1}$, $\V{\beta} \perp \V{1}$, and $\V{\delta} \perp \V{\beta}$.


\section{Intuitive Idea Behind Maximum Likelihood}

Let $\M{M} \in \mathbb{R}^{n \times B}$ where $\M{M}_{ib} = m_{ib}$. Consider principal components analysis with a row centering. Let $\widehat{\alpha}_i = \frac{1}{B} \sum m_{ib}$ and $\widehat{\V{\alpha}} = (\widehat{\alpha}_1,\ldots,\widehat{\alpha}_n)^T$. The row centered $\M{M}$ is
\begin{equation*}
\M{M}' = \M{M} - \V{\alpha}\V{1}^T.
\end{equation*}
Let $\widehat{\V{\beta}}$ be the column means of $\M{M}'$, $\widehat{\V{d}}$ be the first singular values of the column centered $\M{M}'$, and $\widehat{\V{\delta}}$ be the first singular vector.

\section{Formal Derivation of Maximum Likelihood Estimates}

We seek
\begin{equation*}
\argmin{\V{\alpha},\V{\beta},\V{\delta},\V{d}} \sum_{i=1}^n || \V{m}_i - \V{\beta} - \alpha_i\V{1} - d_i\V{\delta}||_2^2.
\end{equation*}
Fixing all other parameters we have
\begin{align*}
\widehat{\alpha}_i &= \frac{1}{B} \sum_{b=1}^B (m_{ib} - \beta_{b} - d_i\delta_b)\\
&= \frac{1}{B} \sum_{b=1}^B m_{ib} - \frac{1}{B}\sum_{b=1}^B \beta_{b} - d_i\frac{1}{B}\sum_{b=1}^B\delta_b\\
&= \frac{1}{B} \sum_{b=1}^B m_{ib}\\
&= \bar{m}_i
\end{align*}
Now we must find
\begin{equation*}
\argmin{\V{\beta},\V{\delta},\V{d}} \sum_{i=1}^n || \V{x}_i - \V{\beta} - d_i\V{\delta}||_2^2.
\end{equation*}
where $\V{x}_i = \V{m}_{i} - \widehat{\alpha}_i\V{1}$. We have
\begin{align*}
\widehat{\beta}_b &= \frac{1}{n}\sum_{i=1}^n (x_{ib} - d_i\delta_b)\\
&= \frac{1}{n}\sum_{i=1}^n x_{ib} - \delta_b \frac{1}{n} \sum_{i=1}^n d_i)\\
&= \frac{1}{n}\sum_{i=1}^n x_{ib}\\
&= \left(\frac{1}{n}\sum_{i=1}^n m_{ib}\right) - n\widehat{\alpha}_b
\end{align*}
Finally we have
\begin{equation*}
\argmin{\V{\delta},\V{d}} \sum_{i=1}^n || \V{x}_i - d_i\V{\delta}||_2^2.
\end{equation*}
where $\V{x}_i = \V{m}_{i} - \widehat{\alpha}_i\V{1} - \widehat{\V{\beta}}$. This final minimization is achieved using a singular value decomposition where $\V{\delta}$ is the first singular vector and $\V{d}$ is the vector of first singular values.



\section{Case Where $\V{\delta}$ Is Known}

%\bibliographystyle{plainnat}
%\bibliography{refs}
Recall the model is
\begin{equation*}
\V{m}_i = \V{\beta} + \alpha_i \V{1} + d_i \V{\delta} + \V{\sigma}_i.
\end{equation*}
With $\V{\delta}$ known, the model is still not identifiable. For example,
\begin{align*}
\V{m}_i &= (\V{\beta} + c\V{\delta}) + \alpha_i \V{1} + (d_i - c) \V{\delta} + \V{\sigma}_i\\
\V{m}_i &= (\V{\beta} - c\V{1}) + (\alpha_i + c)\V{1} + d_i\V{\delta} + \V{\sigma}_i\\
\end{align*}
Note that the third equation in the original identifiability problem is no longer an issue because $\V{\delta}$ is known. For identifiability we assume $\V{\beta} \perp \V{1}$ and $\V{\beta} \perp \V{\delta}$.

Let $\M{Y}_i=\V{m}_i$ and $\M{X}_i = (\V{1},\V{\delta})$. Then our estimates of $\alpha_i$ and $d_i$ are
\begin{equation*}
\begin{pmatrix}
\widehat{\alpha}_i \\\widehat{d}_i
\end{pmatrix}
 = (\M{X}_i^T\M{X}_i)^{-1}\M{X}_i^T\M{Y}_i
\end{equation*}
The residuals for the fit are
\begin{equation*}
\V{r}_i = \M{Y}_i - \M{X}_i\begin{pmatrix}
\widehat{\alpha}_i \\\widehat{d}_i
\end{pmatrix}
\end{equation*}
and 
\begin{equation*}
\V{\beta} = \frac{1}{n}\sum \V{r}_i
\end{equation*}
$\V{\beta}$ is orthogonal to $\V{\delta}$ and $\V{1}$ because the $\V{r}_i$ are orthogonal to $\V{\delta}$ and $\V{1}$ because these are the columns of the design matrix and $\V{r}_i$ are the residuals.
\end{document}

